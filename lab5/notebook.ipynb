{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Klasyfikacja niezbalansowana i anomaly detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poza standardowymi narzędziami do klasyfikacji tabelarycznej użyjemy bibliotek:\n",
    "\n",
    "1. [Imbalanced-learn](https://imbalanced-learn.org/stable/index.html) - biblioteka implementująca różne algorytmy undersamplingu i oversamplingu\n",
    "2. [PyOD](https://pyod.readthedocs.io/en/latest/index.html) - biblioteka implementująca mnóstwo algorytmów outlier detection\n",
    "3. [XGBoost](https://xgboost.readthedocs.io/en/stable/) - oficjalna implementacja algorytmu XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klasyfikacja umiarkowanie niezbalansowana\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Najpierw wykorzystamy zbiór danych [Polish companies bankruptcy](https://archive.ics.uci.edu/ml/datasets/Polish+companies+bankruptcy+data). Dotyczy on klasyfikacji, na podstawie danych z raportów finansowych, czy firma zbankrutuje w ciągu najbliższych kilku lat. Jest to zadanie szczególnie istotne dla banków, funduszy inwestycyjnych, firm ubezpieczeniowych itp., które z tego powodu zatrudniają licznie data scientistów. Zbiór zawiera 64 cechy, obliczone przez ekonomistów, którzy stworzyli ten zbiór, opisane na stronie UCI.\n",
    "\n",
    "Wykorzystamy podzbiór, w którym na podstawie finansowych firmy po 3 latach monitorowania chcemy przewidywać, czy firma zbankrutuje w ciągu najbliższych 3 lat. Jest to dość realistyczny horyzont czasowy, a przy tym największy z podzbiorów.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attr1</th>\n",
       "      <th>Attr2</th>\n",
       "      <th>Attr3</th>\n",
       "      <th>Attr4</th>\n",
       "      <th>Attr5</th>\n",
       "      <th>Attr6</th>\n",
       "      <th>Attr7</th>\n",
       "      <th>Attr8</th>\n",
       "      <th>Attr9</th>\n",
       "      <th>Attr10</th>\n",
       "      <th>...</th>\n",
       "      <th>Attr55</th>\n",
       "      <th>Attr56</th>\n",
       "      <th>Attr57</th>\n",
       "      <th>Attr58</th>\n",
       "      <th>Attr59</th>\n",
       "      <th>Attr60</th>\n",
       "      <th>Attr61</th>\n",
       "      <th>Attr62</th>\n",
       "      <th>Attr63</th>\n",
       "      <th>Attr64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.174190</td>\n",
       "      <td>0.41299</td>\n",
       "      <td>0.14371</td>\n",
       "      <td>1.3480</td>\n",
       "      <td>-28.9820</td>\n",
       "      <td>0.60383</td>\n",
       "      <td>0.219460</td>\n",
       "      <td>1.1225</td>\n",
       "      <td>1.1961</td>\n",
       "      <td>0.46359</td>\n",
       "      <td>...</td>\n",
       "      <td>127280.0</td>\n",
       "      <td>0.163960</td>\n",
       "      <td>0.375740</td>\n",
       "      <td>0.83604</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>9.7145</td>\n",
       "      <td>6.2813</td>\n",
       "      <td>84.291</td>\n",
       "      <td>4.3303</td>\n",
       "      <td>4.0341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.146240</td>\n",
       "      <td>0.46038</td>\n",
       "      <td>0.28230</td>\n",
       "      <td>1.6294</td>\n",
       "      <td>2.5952</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.171850</td>\n",
       "      <td>1.1721</td>\n",
       "      <td>1.6018</td>\n",
       "      <td>0.53962</td>\n",
       "      <td>...</td>\n",
       "      <td>3387.8</td>\n",
       "      <td>0.027516</td>\n",
       "      <td>0.271000</td>\n",
       "      <td>0.90108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.9882</td>\n",
       "      <td>4.1103</td>\n",
       "      <td>102.190</td>\n",
       "      <td>3.5716</td>\n",
       "      <td>5.9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.22612</td>\n",
       "      <td>0.48839</td>\n",
       "      <td>3.1599</td>\n",
       "      <td>84.8740</td>\n",
       "      <td>0.19114</td>\n",
       "      <td>0.004572</td>\n",
       "      <td>2.9881</td>\n",
       "      <td>1.0077</td>\n",
       "      <td>0.67566</td>\n",
       "      <td>...</td>\n",
       "      <td>20453.0</td>\n",
       "      <td>0.007639</td>\n",
       "      <td>0.000881</td>\n",
       "      <td>0.99236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.7742</td>\n",
       "      <td>3.7922</td>\n",
       "      <td>64.846</td>\n",
       "      <td>5.6287</td>\n",
       "      <td>4.4581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.024526</td>\n",
       "      <td>0.43236</td>\n",
       "      <td>0.27546</td>\n",
       "      <td>1.7833</td>\n",
       "      <td>-10.1050</td>\n",
       "      <td>0.56944</td>\n",
       "      <td>0.024526</td>\n",
       "      <td>1.3057</td>\n",
       "      <td>1.0509</td>\n",
       "      <td>0.56453</td>\n",
       "      <td>...</td>\n",
       "      <td>5012.6</td>\n",
       "      <td>0.048398</td>\n",
       "      <td>0.043445</td>\n",
       "      <td>0.95160</td>\n",
       "      <td>0.142980</td>\n",
       "      <td>4.2286</td>\n",
       "      <td>5.0528</td>\n",
       "      <td>98.783</td>\n",
       "      <td>3.6950</td>\n",
       "      <td>3.4844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.188290</td>\n",
       "      <td>0.41504</td>\n",
       "      <td>0.34231</td>\n",
       "      <td>1.9279</td>\n",
       "      <td>-58.2740</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.233580</td>\n",
       "      <td>1.4094</td>\n",
       "      <td>1.3393</td>\n",
       "      <td>0.58496</td>\n",
       "      <td>...</td>\n",
       "      <td>13730.0</td>\n",
       "      <td>0.176480</td>\n",
       "      <td>0.321880</td>\n",
       "      <td>0.82635</td>\n",
       "      <td>0.073039</td>\n",
       "      <td>2.5912</td>\n",
       "      <td>7.0756</td>\n",
       "      <td>100.540</td>\n",
       "      <td>3.6303</td>\n",
       "      <td>4.6375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Attr1    Attr2    Attr3   Attr4    Attr5    Attr6     Attr7   Attr8  \\\n",
       "0  0.174190  0.41299  0.14371  1.3480 -28.9820  0.60383  0.219460  1.1225   \n",
       "1  0.146240  0.46038  0.28230  1.6294   2.5952  0.00000  0.171850  1.1721   \n",
       "2  0.000595  0.22612  0.48839  3.1599  84.8740  0.19114  0.004572  2.9881   \n",
       "3  0.024526  0.43236  0.27546  1.7833 -10.1050  0.56944  0.024526  1.3057   \n",
       "4  0.188290  0.41504  0.34231  1.9279 -58.2740  0.00000  0.233580  1.4094   \n",
       "\n",
       "    Attr9   Attr10  ...    Attr55    Attr56    Attr57   Attr58    Attr59  \\\n",
       "0  1.1961  0.46359  ...  127280.0  0.163960  0.375740  0.83604  0.000007   \n",
       "1  1.6018  0.53962  ...    3387.8  0.027516  0.271000  0.90108  0.000000   \n",
       "2  1.0077  0.67566  ...   20453.0  0.007639  0.000881  0.99236  0.000000   \n",
       "3  1.0509  0.56453  ...    5012.6  0.048398  0.043445  0.95160  0.142980   \n",
       "4  1.3393  0.58496  ...   13730.0  0.176480  0.321880  0.82635  0.073039   \n",
       "\n",
       "   Attr60  Attr61   Attr62  Attr63  Attr64  \n",
       "0  9.7145  6.2813   84.291  4.3303  4.0341  \n",
       "1  5.9882  4.1103  102.190  3.5716  5.9500  \n",
       "2  6.7742  3.7922   64.846  5.6287  4.4581  \n",
       "3  4.2286  5.0528   98.783  3.6950  3.4844  \n",
       "4  2.5912  7.0756  100.540  3.6303  4.6375  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.io import arff\n",
    "\n",
    "data = arff.loadarff(\"polish_companies_bankruptcy_3_year_data.arff\")\n",
    "\n",
    "df = pd.DataFrame(data[0])\n",
    "y = df.pop(\"class\").astype(int)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 1 (1 punkt)**\n",
    "\n",
    "1. Zwizualizuj brakujące ilość brakujących danych na wykresie słupkowym (bar plot).\n",
    "2. Zwizualizuj rozkład klas na wykresie.\n",
    "3. Usuń cechę `Attr37`, mającą dużo wartości brakujących.\n",
    "4. Dokonaj podziału na zbiór treningowy i testowy w proporcjach 75%-25%, ze stratyfikacją. Pamiętaj o `random_state=0`.\n",
    "5. Zbuduj i zastosuj pipeline (`make_pipeline`) do czyszczenia danych, składający się z:\n",
    "   - uzupełnienia wartości brakujących wartością średnią (`SimpleImputer`)\n",
    "   - standaryzacji danych (`StandardScaler`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "missing_counts = df.isnull().sum()\n",
    "missing_counts = missing_counts[missing_counts > 0]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "missing_counts.plot(kind='bar')\n",
    "plt.title('Missing Values in Columns')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Class distribution'}, xlabel='Class (defaulted or not)', ylabel='Class percentage'>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y.value_counts(normalize=True).plot.bar(\n",
    "    title=\"Class distribution\",\n",
    "    rot=0,\n",
    "    xlabel=\"Class (defaulted or not)\",\n",
    "    ylabel=\"Class percentage\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"Attr37\" in df.columns:\n",
    "    df.pop('Attr37')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    df, y, stratify=y, test_size=0.25, random_state=0)\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    SimpleImputer(),\n",
    "    StandardScaler(),\n",
    ")\n",
    "\n",
    "X_train = pipeline.fit_transform(x_train)\n",
    "X_test = pipeline.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standaryzacja była szczególnie ważna, bo metody undersamplingu i oversamplingu są oparte o najbliższych sąsiadów.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost-sensitive learning i threshold tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jako naszego algorytmu użyjemy lasu losowego (Random Forest). Dla przypomnienia, jest on oparty o **uczenie zespołowe (ensemble learning)**, w którym uśredniamy decyzje wielu klasyfikatorów bazowych. Są to drzewa decyzyjne. Losujemy w nim **próbki bootstrapowe (bootstrap samples)**, czyli losujemy z powtórzeniami tyle punktów, ile wynosi rozmiar naszego zbioru. Dla każdej losujemy także podzbiór cech, typowo tyle, ile wynosi pierwiastek kwadratowy z liczby wszystkich cech. Następnie trenujemy drzewa decyzyjne na takich wylosowanych podzbiorach. Decyzja klasyfikatora jest podejmowana przez głosowanie drzew (w klasyfikacji) lub ich uśrednienie (w regresji).\n",
    "\n",
    "W wielu zastosowaniach dużą zaletą lasów losowych jest ich niska podatność na tuning hiperparametrów, tzw. **tunability**. Algorytmy o wysokim tunability (np. SVM) są podatne na dobór hiperparametrów i wymagają jego zastosowania, żeby osiągnąć dobre wyniki. Random Forest działa typowo doskonale z domyślnymi hiperparametrami, co najwyżej warto czasem ustawić większą liczbę drzew, niż domyślna. Ciekawe artykuły w tej kwestii to:\n",
    "\n",
    "> Probst, Philipp, Anne-Laure Boulesteix, and Bernd Bischl. _\"Tunability: Importance of hyperparameters of machine learning algorithms.\"_ The Journal of Machine Learning Research 20.1 (2019): 1934-1965. [link](https://www.jmlr.org/papers/volume20/18-444/18-444.pdf)\n",
    "\n",
    "> Probst, Philipp, Marvin N. Wright, and Anne‐Laure Boulesteix. _\"Hyperparameters and tuning strategies for random forest.\"_ Wiley Interdisciplinary Reviews: data mining and knowledge discovery 9.3 (2019): e1301. [link](https://arxiv.org/pdf/1804.03515.pdf)\n",
    "\n",
    "Dzięki wykorzystaniu Random Forest zasadniczo nie będziemy potrzebować tuningu hiperparametrów dla klasyfikatora. Nadaje się też dobrze do klasyfikacji niezbalansowanej: drzewa decyzyjne łatwo integrują ważenie klas w proces treningu, a uśrednianie decyzji mocno zmniejsza wariancję błędu.\n",
    "\n",
    "Ze względu na niezbalansowanie zbioru, które jest znaczące, ale nie ekstremalne, wykorzystamy dwie metryki: AUROC oraz F1-score. Ta druga będzie przydatna przy **threshold tuningu**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 87.00%\n",
      "F1-score: 31.17%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "\n",
    "clf_rf = RandomForestClassifier(random_state=0, n_jobs=-1)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf_rf.predict(X_test)\n",
    "y_pred_score = clf_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "auroc = roc_auc_score(y_test, y_pred_score)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"AUROC: {100 * auroc:.2f}%\")\n",
    "print(f\"F1-score: {100 * f1:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUROC wydaje się niezłe, ale F1-score pozostawia wiele do życzenia. Zobaczmy, czy **cost-sensitive learning** coś zmieni. Skorzystamy z domyślnej heurystyki do ważenia klas `\"balanced\"`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 89.16%\n",
      "F1-score: 27.03%\n"
     ]
    }
   ],
   "source": [
    "clf_rf_csl = RandomForestClassifier(\n",
    "    class_weight=\"balanced\", random_state=0, n_jobs=-1)\n",
    "clf_rf_csl.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf_rf_csl.predict(X_test)\n",
    "y_pred_score = clf_rf_csl.predict_proba(X_test)[:, 1]\n",
    "\n",
    "auroc = roc_auc_score(y_test, y_pred_score)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"AUROC: {100 * auroc:.2f}%\")\n",
    "print(f\"F1-score: {100 * f1:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jedna metryka rośnie, druga maleje - tak też się może zdarzyć. Takie sytuacje są zawsze ciekawe, bo pokazują różne aspekty tego, jak radzi sobie nasz klasyfikator. F1-score łączy precyzję i czułość, więc warto przeanalizować to głębiej.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF\n",
      "  Precision: 80.00%\n",
      "  Recall: 19.35%\n",
      "\n",
      "RF with cost-sensitive learning\n",
      "  Precision: 83.33%\n",
      "  Recall: 16.13%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "print(\"RF\")\n",
    "rf_precision = precision_score(y_test, clf_rf.predict(X_test))\n",
    "rf_recall = recall_score(y_test, clf_rf.predict(X_test))\n",
    "print(f\"  Precision: {100 * rf_precision:.2f}%\")\n",
    "print(f\"  Recall: {100 * rf_recall:.2f}%\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"RF with cost-sensitive learning\")\n",
    "rf_csl_precision = precision_score(y_test, clf_rf_csl.predict(X_test))\n",
    "rf_csl_recall = recall_score(y_test, clf_rf_csl.predict(X_test))\n",
    "print(f\"  Precision: {100 * rf_csl_precision:.2f}%\")\n",
    "print(f\"  Recall: {100 * rf_csl_recall:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z cost-sensitive learningiem predykcje prawdopodobieństwa co prawda są lepsze (bo mamy wyższy AUROC), ale i precyzja, i czułość spadły. No i w obu przypadkach mamy naprawdę niski recall!\n",
    "\n",
    "Coś trzeba z tym zrobić. Skoro F1-score to metryka binarna, to najłatwiej zmienić próg klasy pozytywnej, czyli zrobić threshold tuning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 2 (1.5 punktu)**\n",
    "\n",
    "Zaimplementuj threshold tuning z pomocą walidacji skrośnej. Skorzystaj z funkcji `thresholded_f1_score()`, która jest gotową metryką, obliczającą F1-score dla podanych prawdopodobieństw klasy pozytywnej i progu klasyfikacji.\n",
    "\n",
    "1. Stwórz listę progów [0.1, 0.15, 0.2, .., 0.5]\n",
    "2. Dla każdego progu stwórz nowy obiekt metryki z pomocą funkcji `make_scorer()`. Pamiętaj, że większa wartość jest lepsza i potrzebujemy prawdopodobieństw. Trzeba też podać wartość dla naszego progu (`threshold`) z pomocą `**kwargs`.\n",
    "3. Oblicz wyniki walidacji skrośnej z pomocą funkcji `cross_val_score` dla Random Forest z cost-sensitive tuning. Wykorzystaj 5-fold CV. Funkcja ta zwraca wyniki dla wszystkich foldów - oblicz średni wynik.\n",
    "4. Zwizualizuj na wykresie wyniki F1-score dla poszczególnych progów. Pamiętaj o opisaniu osi i tytule wykresu.\n",
    "5. Dla optymalnego progu oblicz i wypisz F1-score, precision i recall. Próg, dla którego osiągnięto najwyższy F1-score, można łatwo wyciągnąć z pomocą `np.argmax()`.\n",
    "6. Skomentuj zmianę w precision i recall. Czy twoim zdaniem warto dokonać takiej zmiany w przypadku tego zbioru, tj. przewidywania, czy spółka zbankrutuje?\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def thresholded_f1_score(y_true, y_score, threshold: float, **kwargs) -> float:\n",
    "    y_pred = y_score >= threshold\n",
    "    return f1_score(y_true, y_pred, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.15\n",
      "F1 score: 45.38%\n",
      "Precision: 43.38%\n",
      "Recall: 47.58%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def thresholded_f1_score(y_true, y_pred, threshold=0.5):\n",
    "    y_pred = (y_pred >= threshold).astype(int)\n",
    "    return f1_score(y_true, y_pred)\n",
    "\n",
    "\n",
    "thresholds = np.arange(0.1, 0.5, 0.05)\n",
    "scores = []\n",
    "for threshold in thresholds:\n",
    "    scorer = make_scorer(\n",
    "        thresholded_f1_score, threshold=threshold, response_method=\"predict_proba\")\n",
    "    score = np.mean(\n",
    "        cross_val_score(clf_rf_csl, X_train, y_train,\n",
    "                        scoring=scorer, cv=5, n_jobs=-1)\n",
    "    )\n",
    "    scores.append(score)\n",
    "\n",
    "plt.plot(thresholds, scores)\n",
    "plt.title(\"F1 score vs. threshold\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"F1 score\")\n",
    "plt.show()\n",
    "\n",
    "best_threshold = thresholds[np.argmax(scores)]\n",
    "print(f\"Best threshold: {best_threshold:.2f}\")\n",
    "y_pred = clf_rf_csl.predict_proba(X_test)[:, 1]\n",
    "y_pred = (y_pred >= best_threshold).astype(int)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(f\"F1 score: {100 * f1:.2f}%\")\n",
    "print(f\"Precision: {100 * precision:.2f}%\")\n",
    "print(f\"Recall: {100 * recall:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wartości precision i recall niemal się odwróciły i w rezultacie dostaliśmy wysoka czulosc (na czym nam zalezało) kosztem niskiej precyzji. Jest to wynik calkiem niezły, natomiast dalej mamy bardzo duzo FP, co moze daloby sie zminimalizować.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersampling, oversampling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Być może klasa większościowa, której jest 95%, jest mocno zaszumiona i są tam przykłady, które warto byłoby usunąć. Czemu tak może być?\n",
    "\n",
    "Pamiętajmy, że klasa pozytywna to spółki, które zbankrutują w ciągu najbliższych 3 lat. Przy granicy decyzyjnej w klasie dominującej mogą być na przykład startupy o dużym ryzyku, które nie zbankrutowały, ale było to kwestią dobrej koniunktury i szczęśliwego trafu tych spółek. Równie dobrze mogłyby upaść przez niskie zasoby twarde czy rosnące koszty. Można je potraktować jak mało miarodajny szum, który tylko z przyczyn dość losowych nie stał się klasą pozytywną (tj. spółkami, które zamknęły działalność).\n",
    "\n",
    "Dla uproszczenia w tym i dalszych zadaniach skorzystamy z funkcji `assess_rf_performance()`, żeby łatwo sprawdzać AUROC i F1-score klasyfikatorów.\n",
    "\n",
    "Najpierw zastosujemy algorytm Edited Nearest Neighbors (ENN) z domyślnymi parametrami:\n",
    "\n",
    "- `k=3`\n",
    "- `kind_sel=\"all\"` (wszyscy sąsiedzi muszą być z klasy dominującej, aby punkt pozostał w zbiorze)\n",
    "\n",
    "Biblioteka imbalanced-learn opiera się o metodę `.fit_resample()`, która zwraca zmodyfikowany zbiór uczący (z usuniętymi/dodatkowymi próbkami). Implementuje także zmodyfikowany `Pipeline`, bo ten domyślny ze Scikit-learn nie wspierałby takiej metody. Warto pamiętać o tym, żeby tworzyć nowe zmienne dla zmodyfikowanych zbiorów, bo inaczej trzeba by wykonywać duże części notebooka na nowo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_rf_performance(estimator: RandomForestClassifier, X_test, y_test) -> None:\n",
    "    y_score = estimator.predict_proba(X_test)[:, 1]\n",
    "    y_pred = estimator.predict(X_test)\n",
    "    auroc = roc_auc_score(y_test, y_score)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"AUROC: {100 * auroc:.2f}%\")\n",
    "    print(f\"F1-score: {100 * f1:.2f}%\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples before ENN: 7877\n",
      "Samples after ENN: 7005\n",
      "AUROC: 87.46%\n",
      "F1-score: 28.38%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "\n",
    "\n",
    "enn = EditedNearestNeighbours()\n",
    "print(f\"Samples before ENN: {len(X_train)}\")\n",
    "X_train_enn, y_train_enn = enn.fit_resample(X_train, y_train)\n",
    "print(f\"Samples after ENN: {len(X_train_enn)}\")\n",
    "\n",
    "clf_rf_csl = RandomForestClassifier(\n",
    "    class_weight=\"balanced\", random_state=0, n_jobs=-1)\n",
    "clf_rf_csl.fit(X_train_enn, y_train_enn)\n",
    "\n",
    "assess_rf_performance(clf_rf_csl, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wcześniej AUROC wynosiło 89.30%, a F1-score 28.00%. Mamy spadek obu metryk - niedobrze! Usunęliśmy jednak około 10% zbioru, może to za dużo?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 3 (1.5 punktu)**\n",
    "\n",
    "1. Dokonaj tuningu hiperparametrów ENN:\n",
    "   - stwórz siatkę hiperparametrów:\n",
    "     - liczba sąsiadów: `[1, 3, 5]`\n",
    "     - tryb wyboru punktów: `[\"all\", \"mode\"]`\n",
    "   - przed użyciem `GridSearchCV` stwórz pipeline (ten z biblioteki imbalanced-learn), łączący ENN i Random Forest\n",
    "   - wybierz klasyfikator o najwyższym AUROC\n",
    "   - wykorzystaj 10-fold CV - przy zbiorach niezbalansowanych często daje to dokładniejsze oszacowanie\n",
    "   - pamiętaj, żeby podać, którego elementu pipeline'u dotyczą hiperparametry w siatce (np. `enn__n_neighbors`)\n",
    "2. Wypisz znalezione optymalne wartości hiperparametrów. Sprawdź wyniki na zbiorze testowym.\n",
    "3. Czy usuwamy punkty agresywniej, czy bardziej konwerwatywnie? Zweryfikuj swoją intuicję, sprawdzając liczność zbioru przed i po zastosowaniu ENN z optymalnymi hiperparametrami.\n",
    "4. Czy undersampling ostatecznie poprawił wynik? Czy twoim zdaniem warto tu zastosować taką technikę?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'enn__kind_sel': 'mode', 'enn__n_neighbors': 5}\n",
      "AUROC: 88.17%\n",
      "F1-score: 27.03%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.pipeline import Pipeline as IMBPipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'enn__n_neighbors': [1, 3, 5],\n",
    "    'enn__kind_sel': ['all', 'mode'],\n",
    "}\n",
    "pipeline = IMBPipeline(\n",
    "    steps=[\n",
    "        ('enn', EditedNearestNeighbours()),\n",
    "        ('clf', RandomForestClassifier(\n",
    "            class_weight=\"balanced\", random_state=0, n_jobs=-1)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    pipeline,\n",
    "    params,\n",
    "    scoring='roc_auc',\n",
    "    cv=10,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "grid.fit(X_train, y_train)\n",
    "best_model = grid.best_estimator_\n",
    "print(f\"Best parameters: {grid.best_params_}\")\n",
    "assess_rf_performance(grid.best_estimator_, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples before ENN: 7877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples after ENN: 7858\n"
     ]
    }
   ],
   "source": [
    "print(f\"Samples before ENN: {len(X_train)}\")\n",
    "X_train_enn, y_train_enn = best_model.named_steps['enn'].fit_resample(\n",
    "    X_train, y_train)\n",
    "print(f\"Samples after ENN: {len(X_train_enn)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z wyników wynika, ze nie usuwamy niemal prawie w ogole probek, poza paroma wyjatkami. Otrzymane tak wyniki nie sa duzo lepsze i mysle ze wynika to z faktu, ze w tym przypadku undersampling nie jest najlepszym rozwiazaniem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Być może oversampling da nam większe korzyści, w końcu klasy pozytywnej jest naprawdę mało. Wypróbujmy najpierw SMOTE z domyślnymi hiperparametrami.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples before SMOTE: 7877\n",
      "Samples after SMOTE: 15012\n",
      "AUROC: 88.41%\n",
      "F1-score: 42.65%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "smote = SMOTE(random_state=0)\n",
    "print(f\"Samples before SMOTE: {len(X_train)}\")\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "print(f\"Samples after SMOTE: {len(X_train_smote)}\")\n",
    "\n",
    "clf_rf_csl = RandomForestClassifier(\n",
    "    class_weight=\"balanced\", random_state=0, n_jobs=-1)\n",
    "clf_rf_csl.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "assess_rf_performance(clf_rf_csl, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jest definitywnie lepiej! Liczba przykładów z klasy pozytywnej wzrosła bardzo mocno, ale dzięki skalowalności lasu losowego nie jest to drastycznie odczuwalne. Za to F1-score bardzo wzrósł, bo zwiększyliśmy znacząco wagę klasy mniejszościowej, i to zagęszczając ją w przestrzeni zbioru danych. Dzięki temu i FP, i FN spadną.\n",
    "\n",
    "Imbalanced-learn domyślnie generuje tyle klasy mniejszościowej, żeby było jej tyle samo, co dominującej. Prawie zawsze powoduje to overfitting - zweryfikujmy to.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "AUROC: 100.00%\n",
      "F1-score: 100.00%\n",
      "\n",
      "\n",
      "Test metrics\n",
      "AUROC: 88.41%\n",
      "F1-score: 42.65%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train metrics\")\n",
    "assess_rf_performance(clf_rf_csl, X_train, y_train)\n",
    "print()\n",
    "print(\"Test metrics\")\n",
    "assess_rf_performance(clf_rf_csl, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jest to wręcz tragiczny overfitting! Definitywnie trzeba tutaj tuningu. Imbalanced-learn pozwala na to poprzez parametr `sampling_strategy`. Jeżeli jest to liczba, to oznacza stosunek liczby przykładów klasy mniejszościowej do liczby przykładów klasy większościowej po oversamplingu.\n",
    "\n",
    "Przykładowo, domyślne ustawienia odpowiadają `sampling_strategy=1`, czyli:\n",
    "\n",
    "$$\n",
    "\\large\n",
    "\\frac{n_{minority}}{n_{majority}} = 1 \\longrightarrow n_{minority} = n_{majority}\n",
    "$$\n",
    "\n",
    "Żeby zmniejszyć overfitting, trzeba generować mniej klasy pozytywnej, czyli zmniejszyć tę proporcję. Dodatkowo możemy zmienić wartość najbliższych sąsiadów - mniejsza liczba będzie skutkować generacją bardziej wiernych lokalnie próbek, a większa zwiększy różnorodność.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 4 (2 punkty)**\n",
    "\n",
    "Ze względu na koszt obliczeniowy połączenia 10-fold CV i metod opartych o sąsiedztwo można wykonać **step-wise tuning**, w którym robimy walidację skrośną po kolei dla parametrów, zamiast sprawdzać wszystkie kombinacje po kolei. Nie daje to gwarancji optymalności, ale typowo działa bardzo dobrze, a przy tym jest dużo szybsze. Jest to typowo stosowane w boostingu, który ma bardzo dużo hiperparametrów, ale także przy innych kosztownych algorytmach. Dobrze opisuje to [ten artykuł](https://medium.com/optuna/lightgbm-tuner-new-optuna-integration-for-hyperparameter-optimization-8b7095e99258).\n",
    "\n",
    "Dokonaj po kolei tuningu:\n",
    "\n",
    "- liczby sąsiadów w SMOTE w zakresie `[1, 2, 3, 4, 5]`\n",
    "- ilości klasy pozytywnej w zakresie od 0.25 do 1 z krokiem 0.25 (może się przydać `np.linspace()` albo `np.arange()`)\n",
    "\n",
    "Zwróć uwagę na:\n",
    "\n",
    "- 10-fold CV\n",
    "- ustawienie `random_state=0`\n",
    "- przyda się ustawić `verbose=4`, żeby mieć logi z wykonania, bo będzie się to chwilę liczyć\n",
    "\n",
    "Sprawdź wyniki obu pipeline'ów (z osobna) na zbiorze treningowym oraz testowym. Wytrenuj także łączny pipeline, wykorzystując oba znalezione parametry naraz, i sprawdź jego wyniki.\n",
    "\n",
    "Pamiętaj, że nie trzeba przetrenowywać klasyfikatorów na finalnych hiperparametrach - obiekt `GridSearchCV` też ma metodę `.predict()`, w któryj pod spodem użyje modelu z najlepszymi znalezionymi wartościami hiperparametrów.\n",
    "\n",
    "Skomentuj:\n",
    "\n",
    "- czy wynik się poprawił?\n",
    "- czy zmniejszono lub wyeliminowano overfitting w którymś przypadku?\n",
    "- czy warto było tune'ować oba parametry?\n",
    "- czy połączenie parametrów poprawiło wynik?\n",
    "\n",
    "Oszacuj, ile wolniej wykonywałby się grid search na pełnej, kwadratowej siatce hiperparametrów. Oblicz liczbę modeli, którą trzeba by wytrenować w obu przypadkach (step-wise oraz na pełnej siatce) przy 10-fold CV, i przyjmij stały średni czas na jeden fold według logów z treningu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "[CV 7/10] END .............smote__k_neighbors=1;, score=0.915 total time=   8.8s\n",
      "[CV 4/10] END .............smote__k_neighbors=1;, score=0.898 total time=   8.9s\n",
      "[CV 1/10] END .............smote__k_neighbors=1;, score=0.841 total time=   9.1s\n",
      "[CV 8/10] END .............smote__k_neighbors=1;, score=0.893 total time=   9.0s\n",
      "[CV 2/10] END .............smote__k_neighbors=1;, score=0.879 total time=   9.1s\n",
      "[CV 5/10] END .............smote__k_neighbors=1;, score=0.852 total time=   9.2s\n",
      "[CV 6/10] END .............smote__k_neighbors=1;, score=0.902 total time=   9.3s\n",
      "[CV 3/10] END .............smote__k_neighbors=1;, score=0.844 total time=   9.6s\n",
      "[CV 9/10] END .............smote__k_neighbors=1;, score=0.867 total time=   8.3s\n",
      "[CV 1/10] END .............smote__k_neighbors=2;, score=0.843 total time=   8.5s\n",
      "[CV 10/10] END ............smote__k_neighbors=1;, score=0.832 total time=   8.7s\n",
      "[CV 3/10] END .............smote__k_neighbors=2;, score=0.835 total time=   8.8s\n",
      "[CV 2/10] END .............smote__k_neighbors=2;, score=0.851 total time=   9.0s\n",
      "[CV 5/10] END .............smote__k_neighbors=2;, score=0.898 total time=   8.8s\n",
      "[CV 4/10] END .............smote__k_neighbors=2;, score=0.888 total time=   8.9s\n",
      "[CV 6/10] END .............smote__k_neighbors=2;, score=0.908 total time=   8.7s\n",
      "[CV 7/10] END .............smote__k_neighbors=2;, score=0.923 total time=   9.2s\n",
      "[CV 9/10] END .............smote__k_neighbors=2;, score=0.862 total time=   9.4s\n",
      "[CV 3/10] END .............smote__k_neighbors=3;, score=0.837 total time=   9.0s\n",
      "[CV 8/10] END .............smote__k_neighbors=2;, score=0.889 total time=   9.6s\n",
      "[CV 1/10] END .............smote__k_neighbors=3;, score=0.864 total time=   9.3s\n",
      "[CV 10/10] END ............smote__k_neighbors=2;, score=0.864 total time=   9.5s\n",
      "[CV 2/10] END .............smote__k_neighbors=3;, score=0.837 total time=   9.6s\n",
      "[CV 4/10] END .............smote__k_neighbors=3;, score=0.894 total time=   9.6s\n",
      "[CV 5/10] END .............smote__k_neighbors=3;, score=0.877 total time=   9.0s\n",
      "[CV 6/10] END .............smote__k_neighbors=3;, score=0.899 total time=   9.0s\n",
      "[CV 8/10] END .............smote__k_neighbors=3;, score=0.899 total time=   9.0s\n",
      "[CV 9/10] END .............smote__k_neighbors=3;, score=0.849 total time=   8.9s\n",
      "[CV 7/10] END .............smote__k_neighbors=3;, score=0.915 total time=   9.2s\n",
      "[CV 10/10] END ............smote__k_neighbors=3;, score=0.854 total time=   9.3s\n",
      "[CV 1/10] END .............smote__k_neighbors=4;, score=0.860 total time=   9.1s\n",
      "[CV 2/10] END .............smote__k_neighbors=4;, score=0.863 total time=   9.2s\n",
      "[CV 3/10] END .............smote__k_neighbors=4;, score=0.839 total time=   9.0s\n",
      "[CV 5/10] END .............smote__k_neighbors=4;, score=0.876 total time=   8.5s\n",
      "[CV 4/10] END .............smote__k_neighbors=4;, score=0.887 total time=   8.7s\n",
      "[CV 7/10] END .............smote__k_neighbors=4;, score=0.931 total time=   8.6s\n",
      "[CV 6/10] END .............smote__k_neighbors=4;, score=0.902 total time=   9.1s\n",
      "[CV 9/10] END .............smote__k_neighbors=4;, score=0.866 total time=   9.1s\n",
      "[CV 10/10] END ............smote__k_neighbors=4;, score=0.830 total time=   8.9s\n",
      "[CV 8/10] END .............smote__k_neighbors=4;, score=0.908 total time=   9.5s\n",
      "[CV 1/10] END .............smote__k_neighbors=5;, score=0.866 total time=  10.7s\n",
      "[CV 2/10] END .............smote__k_neighbors=5;, score=0.858 total time=  10.7s\n",
      "[CV 4/10] END .............smote__k_neighbors=5;, score=0.882 total time=  10.8s\n",
      "[CV 3/10] END .............smote__k_neighbors=5;, score=0.837 total time=  11.3s\n",
      "[CV 5/10] END .............smote__k_neighbors=5;, score=0.854 total time=  11.4s\n",
      "[CV 7/10] END .............smote__k_neighbors=5;, score=0.918 total time=  11.2s\n",
      "[CV 6/10] END .............smote__k_neighbors=5;, score=0.893 total time=  11.3s\n",
      "[CV 8/10] END .............smote__k_neighbors=5;, score=0.898 total time=  11.0s\n",
      "[CV 9/10] END .............smote__k_neighbors=5;, score=0.877 total time=   4.5s\n",
      "[CV 10/10] END ............smote__k_neighbors=5;, score=0.834 total time=   4.2s\n",
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n",
      "[CV 2/10] END ....smote__sampling_strategy=0.25;, score=0.879 total time=   5.7s\n",
      "[CV 1/10] END ....smote__sampling_strategy=0.25;, score=0.881 total time=   5.8s\n",
      "[CV 5/10] END ....smote__sampling_strategy=0.25;, score=0.876 total time=   5.8s\n",
      "[CV 4/10] END ....smote__sampling_strategy=0.25;, score=0.904 total time=   5.9s\n",
      "[CV 7/10] END ....smote__sampling_strategy=0.25;, score=0.915 total time=   5.9s\n",
      "[CV 3/10] END ....smote__sampling_strategy=0.25;, score=0.832 total time=   6.1s\n",
      "[CV 8/10] END ....smote__sampling_strategy=0.25;, score=0.887 total time=   5.8s\n",
      "[CV 6/10] END ....smote__sampling_strategy=0.25;, score=0.915 total time=   6.4s\n",
      "[CV 9/10] END ....smote__sampling_strategy=0.25;, score=0.883 total time=   4.9s\n",
      "[CV 5/10] END .....smote__sampling_strategy=0.5;, score=0.881 total time=   5.1s\n",
      "[CV 10/10] END ...smote__sampling_strategy=0.25;, score=0.826 total time=   5.6s\n",
      "[CV 1/10] END .....smote__sampling_strategy=0.5;, score=0.870 total time=   6.5s\n",
      "[CV 3/10] END .....smote__sampling_strategy=0.5;, score=0.831 total time=   6.5s\n",
      "[CV 2/10] END .....smote__sampling_strategy=0.5;, score=0.856 total time=   6.9s\n",
      "[CV 4/10] END .....smote__sampling_strategy=0.5;, score=0.901 total time=   6.8s\n",
      "[CV 6/10] END .....smote__sampling_strategy=0.5;, score=0.909 total time=   6.6s\n",
      "[CV 7/10] END .....smote__sampling_strategy=0.5;, score=0.916 total time=   4.0s\n",
      "[CV 9/10] END .....smote__sampling_strategy=0.5;, score=0.879 total time=   6.3s\n",
      "[CV 8/10] END .....smote__sampling_strategy=0.5;, score=0.898 total time=   6.6s\n",
      "[CV 10/10] END ....smote__sampling_strategy=0.5;, score=0.841 total time=   6.2s\n",
      "[CV 1/10] END ....smote__sampling_strategy=0.75;, score=0.865 total time=   7.8s\n",
      "[CV 4/10] END ....smote__sampling_strategy=0.75;, score=0.891 total time=   7.5s\n",
      "[CV 2/10] END ....smote__sampling_strategy=0.75;, score=0.855 total time=   8.0s\n",
      "[CV 3/10] END ....smote__sampling_strategy=0.75;, score=0.839 total time=   8.4s\n",
      "[CV 5/10] END ....smote__sampling_strategy=0.75;, score=0.861 total time=   7.5s\n",
      "[CV 6/10] END ....smote__sampling_strategy=0.75;, score=0.894 total time=   8.3s\n",
      "[CV 7/10] END ....smote__sampling_strategy=0.75;, score=0.915 total time=   8.6s\n",
      "[CV 8/10] END ....smote__sampling_strategy=0.75;, score=0.889 total time=   8.8s\n",
      "[CV 9/10] END ....smote__sampling_strategy=0.75;, score=0.859 total time=   8.8s\n",
      "[CV 10/10] END ...smote__sampling_strategy=0.75;, score=0.835 total time=   8.6s\n",
      "[CV 1/10] END .....smote__sampling_strategy=1.0;, score=0.866 total time=   9.3s\n",
      "[CV 2/10] END .....smote__sampling_strategy=1.0;, score=0.858 total time=   9.6s\n",
      "[CV 3/10] END .....smote__sampling_strategy=1.0;, score=0.837 total time=   9.5s\n",
      "[CV 4/10] END .....smote__sampling_strategy=1.0;, score=0.882 total time=   8.8s\n",
      "[CV 5/10] END .....smote__sampling_strategy=1.0;, score=0.854 total time=   9.1s\n",
      "[CV 6/10] END .....smote__sampling_strategy=1.0;, score=0.893 total time=   8.8s\n",
      "[CV 8/10] END .....smote__sampling_strategy=1.0;, score=0.898 total time=   7.7s\n",
      "[CV 7/10] END .....smote__sampling_strategy=1.0;, score=0.918 total time=   7.8s\n",
      "[CV 9/10] END .....smote__sampling_strategy=1.0;, score=0.877 total time=   6.7s\n",
      "[CV 10/10] END ....smote__sampling_strategy=1.0;, score=0.834 total time=   6.1s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[(&#x27;smote&#x27;, SMOTE(random_state=0)),\n",
       "                                       (&#x27;clf&#x27;,\n",
       "                                        RandomForestClassifier(class_weight=&#x27;balanced&#x27;,\n",
       "                                                               n_jobs=-1,\n",
       "                                                               random_state=0))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;smote__sampling_strategy&#x27;: array([0.25, 0.5 , 0.75, 1.  ])},\n",
       "             scoring=&#x27;roc_auc&#x27;, verbose=4)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[(&#x27;smote&#x27;, SMOTE(random_state=0)),\n",
       "                                       (&#x27;clf&#x27;,\n",
       "                                        RandomForestClassifier(class_weight=&#x27;balanced&#x27;,\n",
       "                                                               n_jobs=-1,\n",
       "                                                               random_state=0))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;smote__sampling_strategy&#x27;: array([0.25, 0.5 , 0.75, 1.  ])},\n",
       "             scoring=&#x27;roc_auc&#x27;, verbose=4)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: Pipeline</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;smote&#x27;,\n",
       "                 SMOTE(random_state=0, sampling_strategy=np.float64(0.25))),\n",
       "                (&#x27;clf&#x27;,\n",
       "                 RandomForestClassifier(class_weight=&#x27;balanced&#x27;, n_jobs=-1,\n",
       "                                        random_state=0))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SMOTE</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>SMOTE(random_state=0, sampling_strategy=np.float64(0.25))</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, n_jobs=-1, random_state=0)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('smote', SMOTE(random_state=0)),\n",
       "                                       ('clf',\n",
       "                                        RandomForestClassifier(class_weight='balanced',\n",
       "                                                               n_jobs=-1,\n",
       "                                                               random_state=0))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'smote__sampling_strategy': array([0.25, 0.5 , 0.75, 1.  ])},\n",
       "             scoring='roc_auc', verbose=4)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_neigh_pipeline = IMBPipeline(\n",
    "    steps=[\n",
    "        ('smote', SMOTE(random_state=0)),\n",
    "        ('clf', RandomForestClassifier(\n",
    "            class_weight=\"balanced\", random_state=0, n_jobs=-1)),\n",
    "    ]\n",
    ")\n",
    "sampling_strat_pipeline = IMBPipeline(\n",
    "    steps=[\n",
    "        ('smote', SMOTE(random_state=0)),\n",
    "        ('clf', RandomForestClassifier(\n",
    "            class_weight=\"balanced\", random_state=0, n_jobs=-1)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "grid_k_neigh = GridSearchCV(\n",
    "    k_neigh_pipeline,\n",
    "    param_grid={\n",
    "        'smote__k_neighbors': [1, 2, 3, 4, 5],\n",
    "    },\n",
    "    scoring='roc_auc',\n",
    "    cv=10,\n",
    "    n_jobs=-1,\n",
    "    verbose=4,\n",
    ")\n",
    "grid_sampling_strat = GridSearchCV(\n",
    "    sampling_strat_pipeline,\n",
    "    param_grid={\n",
    "        'smote__sampling_strategy': np.linspace(0.25, 1, 4),\n",
    "    },\n",
    "    scoring='roc_auc',\n",
    "    cv=10,\n",
    "    n_jobs=-1,\n",
    "    verbose=4,\n",
    ")\n",
    "\n",
    "grid_k_neigh.fit(X_train, y_train)\n",
    "grid_sampling_strat.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for k_neighbors: {'smote__k_neighbors': 4}\n",
      "Best parameters for sampling_strategy: {'smote__sampling_strategy': np.float64(0.25)}\n",
      "Score on train set for the best k_neighbors\n",
      "AUROC: 100.00%\n",
      "F1-score: 100.00%\n",
      "\n",
      "Score on test set for the best k_neighbors\n",
      "AUROC: 89.58%\n",
      "F1-score: 43.72%\n",
      "\n",
      "Score on train set for the best sampling_strategy\n",
      "AUROC: 100.00%\n",
      "F1-score: 100.00%\n",
      "\n",
      "Score on test set for the best sampling_strategy\n",
      "AUROC: 89.65%\n",
      "F1-score: 36.78%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best parameters for k_neighbors: {grid_k_neigh.best_params_}\")\n",
    "print(\n",
    "    f\"Best parameters for sampling_strategy: {grid_sampling_strat.best_params_}\")\n",
    "\n",
    "print(\"Score on train set for the best k_neighbors\")\n",
    "assess_rf_performance(grid_k_neigh, X_train, y_train)\n",
    "\n",
    "print(\"Score on test set for the best k_neighbors\")\n",
    "assess_rf_performance(grid_k_neigh, X_test, y_test)\n",
    "\n",
    "print(\"Score on train set for the best sampling_strategy\")\n",
    "assess_rf_performance(grid_sampling_strat, X_train, y_train)\n",
    "\n",
    "print(\"Score on test set for the best sampling_strategy\")\n",
    "assess_rf_performance(grid_sampling_strat, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final pipeline score on train set\n",
      "AUROC: 100.00%\n",
      "F1-score: 100.00%\n",
      "\n",
      "Final pipeline score on test set\n",
      "AUROC: 89.54%\n",
      "F1-score: 38.60%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_pipeline = IMBPipeline(\n",
    "    steps=[\n",
    "        ('smote', SMOTE(random_state=0, k_neighbors=4, sampling_strategy=0.25)),\n",
    "        ('clf', RandomForestClassifier(\n",
    "            class_weight=\"balanced\", random_state=0, n_jobs=-1)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "final_pipeline.fit(X_train, y_train)\n",
    "print(\"Final pipeline score on train set\")\n",
    "assess_rf_performance(final_pipeline, X_train, y_train)\n",
    "print(\"Final pipeline score on test set\")\n",
    "assess_rf_performance(final_pipeline, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem overfittingu dalej występuje, a wyniki są niewiele lepsze. W przypadku F1-score jest nawet gorszy niz bez step-wise tuningu, co moze byc spowodowane optymalizowaniem pod AUROC. I faktycznie polaczenie dwoch pipelinow polepszylo wynik.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// Obliczenia:\n",
    "\n",
    "Sprawdzenie jednego folda zajęło około 8 sekund. Mieliśmy 10 foldów w dwóch pipelinach; pipeline 1 miał 5 mozliwych parametrow a drugi 4. daje 10*5*8s + 10*4*8s = 720s (12 minut)\n",
    "Sprawdzenie całego grida rozwiązań zajełoby 8s _ 10 _ 5\\* 4 = 1600s (26 minut). Jak widać, step-wise tuning jest dużo szybszy, a przy tym nie daje gorszych wyników.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ostatnią rzeczą, którą możemy tu zrobić, jest połączenie naszych technik. Imbalanced-learn implementuje wygodne połączenie oversamplingu z undersamplingu w module `combine`, np. klasą `SMOTEENN`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 99.86%\n",
      "F1-score: 73.80%\n",
      "\n",
      "AUROC: 87.63%\n",
      "F1-score: 41.88%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "\n",
    "smote_enn_pipeline = IMBPipeline(\n",
    "    [\n",
    "        (\"smoteenn\", SMOTEENN(random_state=0)),\n",
    "        (\n",
    "            \"rf\",\n",
    "            RandomForestClassifier(\n",
    "                class_weight=\"balanced\", random_state=0, n_jobs=-1),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "smote_enn_pipeline.fit(X_train, y_train)\n",
    "\n",
    "assess_rf_performance(smote_enn_pipeline, X_train, y_train)\n",
    "assess_rf_performance(smote_enn_pipeline, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przy domyślnych hiperparametrach, połączenie SMOTE i ENN daje gorsze wyniki niż sam SMOTE. Może jednak to kwestia tuningu?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 5 (0.5 punktu)**\n",
    "\n",
    "Wytrenuj SMOTEENN, wykorzystując optymalne hiperparametry znalezione podczas tuningu ENN oraz SMOTE. Sprawdź wyniki na zbiorze testowym.\n",
    "\n",
    "Porównaj wyniki ENN, SMOTE oraz ich połączenia. Które rozwiązanie wybrałbyś w praktyce i dlaczego?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 86.47%\n",
      "F1-score: 36.36%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "smote_enn_pipeline = IMBPipeline(\n",
    "    [\n",
    "        (\"smoteenn\", SMOTEENN(random_state=0, sampling_strategy=0.25)),\n",
    "        (\n",
    "            \"rf\",\n",
    "            RandomForestClassifier(\n",
    "                class_weight=\"balanced\", random_state=0, n_jobs=-1),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "smote_enn_pipeline.fit(X_train, y_train)\n",
    "\n",
    "assess_rf_performance(smote_enn_pipeline, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 89.54%\n",
      "F1-score: 38.60%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "smote_pipeline = IMBPipeline(\n",
    "    [\n",
    "        (\"smote\", SMOTE(random_state=0, sampling_strategy=0.25, k_neighbors=4)),\n",
    "        (\n",
    "            \"rf\",\n",
    "            RandomForestClassifier(\n",
    "                class_weight=\"balanced\", random_state=0, n_jobs=-1),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "smote_pipeline.fit(X_train, y_train)\n",
    "\n",
    "assess_rf_performance(smote_pipeline, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 88.17%\n",
      "F1-score: 27.03%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "enn_pipeline = IMBPipeline(\n",
    "    [\n",
    "        (\"enn\", EditedNearestNeighbours(n_neighbors=5, kind_sel='mode')),\n",
    "        (\n",
    "            \"rf\",\n",
    "            RandomForestClassifier(\n",
    "                class_weight=\"balanced\", random_state=0, n_jobs=-1),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "enn_pipeline.fit(X_train, y_train)\n",
    "\n",
    "assess_rf_performance(enn_pipeline, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Co ciekawe, rozwiązanie z samym SMOTE daje najlepsze wyniki. SMOTEENN jest troche gorsze, a samo ENN znacznie odstaje jakością. Moze wynika to z tego, ze klasa mniejszowiowa jest bardzo mała i zabieranie jej undersamplingiem nie wpływa dobrze na algorytm. Niemniej jednak, chyba wybrałbym SMOTEENN, bo wydaje się bardziej generalne, a nie odbiega tak bardzo wynikiem od samego SMOTE.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klasyfikacja ekstremalnie niezbalansowana i anomaly detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jako nasz drugi zbiór wykorzystamy [Credit Card Fraud Detection dataset](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud). Został on stworzony przez naukowców z Université Libre de Bruxelles we współpracy z firmą Wordline, obsługującą transakcje finansowe. Jest to największa europejska firma tego typu, i jedna z największych na świecie. Na potrzeby tego datasetu udostępniła transakcje z Europy z września 2013 roku.\n",
    "\n",
    "Jest to ponad 284 tysiące transakcji, z czego zaledwie 492 to transakcje będące wynikiem przestępstwa (fraud transaction). Klasa pozytywna to zatem około 0.172% danych, co wymaga specjalnych algorytmów i metryk. Cechy w zbiorze zostały zanonimizowane za pomocą transformacji PCA, dzięki czemu można było publicznie udostępnić taki zbiór. Jedynie publicznie znane cechy to \"Time\" i \"Amount\". Wszystkie cechy są numeryczne i nie ma wartości brakujących, a dane są najwyższej możliwej jakości (generowane automatycznie, a fraud jest bardzo dokładnie sprawdzany jako przestępstwa), więc jest doskonały do uczenia maszynowego.\n",
    "\n",
    "Warto pamiętać, że chociaż fraud to tak mało danych, to każdy jeden przypadek to bardzo ciężkie przestępstwo, często mogące zrujnować komuś życie, więc wykrycie możliwie jak największej liczby z nich obowiązkiem prawnym firm finansowych. Z tego względu algorytmy stanowią tutaj część systemu, flagujące transakcje jako podejrzane według prawdopodobieństwa. Później następuje weryfikacja ręczna w takich wypadkach.\n",
    "\n",
    "Ze względu na powyższe cechy zbioru, autorzy proponują metrykę **Area Under Precision-Recall Curve (AUPRC)**. Trzeba pamiętać, żeby uważać przy łączeniu jej z under- i oversamplingiem, bo zmieniają one proporcję klasy pozytywnej.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ze względu na bardzo duży rozmiar zbioru został on zmniejszony przez losowy downsampling klasy negatywnej, żeby wszystko liczyło się w rozsąðnym czasie. Co prawda w ten sposób trochę naruszono balans klas i zwiększymy stosunek outlierów, ale ze względów czysto praktycznych jesteśmy do tego zmuszeni.\n",
    "\n",
    "W praktyce też tak się czasem robi - na nic nam potężna ilość danych, jeżeli nie jesteśmy w stanie nic na tym policzyć. Ostatecznie fraud transaction stanowią dalej niecały 1% naszych danych, więc zbiór dalej jest ekstremalnie niezbalansowany i przybliżenie prawdziwych danych jest dobre.\n",
    "\n",
    "Ma to też tę zaletę, że zwalcza zjawisko nazywane **swamping**. Występuje ono w anomaly detection, gdy mamy totalnie za dużo klasy dominującej i nachodzi ona na chmurę punktów z klasy mniejszościowej (anomalii), \"zalewając\" ją. Powoduje to często FP, kiedy te przykłady z klasy dominującej zostają uznane za pozytywne.\n",
    "\n",
    "Standaryzujemy też dane, bo skorzystamy z metod opartych o najbliższych sąsiadów.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"credit_card_fraud_data.parquet\")\n",
    "y = df.pop(\"Class\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df, y, test_size=0.25, random_state=0, stratify=y\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud class percentage: 0.97%\n"
     ]
    }
   ],
   "source": [
    "y_pos_count = (y == 1).sum()\n",
    "y_pos_perc = y_pos_count / len(y)\n",
    "\n",
    "print(f\"Fraud class percentage: {100 * y_pos_perc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Użyjemy po kolei dwóch algorytmów nienadzorowanego outlier detection:\n",
    "\n",
    "- kNN\n",
    "- Isolation Forest\n",
    "\n",
    "Jako wartość parametru `contamination`, czyli oczekiwanej proporcji outlierów, warto zacząć po prostu od ułamka anomalii w zbiorze treningowym, jeżeli jest ona znana.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "\n",
    "def assess_anomaly_detection_model(estimator, X_test, y_test) -> None:\n",
    "    y_pred_score = estimator.predict_proba(X_test)\n",
    "\n",
    "    # in PyOD, .predict_proba() sometimes returns probability distribution,\n",
    "    # and sometimes it returns only probability of being anomaly\n",
    "    if len(y_pred_score.shape) > 1:\n",
    "        y_pred_score = y_pred_score[:, 1]\n",
    "\n",
    "    auprc = average_precision_score(y_test, y_pred_score)\n",
    "    print(f\"AUPRC: {100 * auprc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN metrics\n",
      "AUPRC: 19.98%\n",
      "\n",
      "Isolation Forest metrics\n",
      "AUPRC: 56.49%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyod.models.iforest import IForest\n",
    "from pyod.models.knn import KNN\n",
    "\n",
    "\n",
    "contamination = (y == 1).sum() / len(y)\n",
    "\n",
    "knn = KNN(contamination=contamination, n_jobs=-1)\n",
    "knn.fit(X_train)\n",
    "print(\"kNN metrics\")\n",
    "assess_anomaly_detection_model(knn, X_test, y_test)\n",
    "print()\n",
    "\n",
    "iforest = IForest(\n",
    "    contamination=contamination, behaviour=\"new\", random_state=0, n_jobs=-1\n",
    ")\n",
    "iforest.fit(X_train)\n",
    "print(\"Isolation Forest metrics\")\n",
    "assess_anomaly_detection_model(iforest, X_test, y_test)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kNN wykazuje na pewno potencjał (pamiętajmy, że AUPRC ma typowo bardzo niskie wartości!), ale nasz zbiór jest dość duży, więc czuć wolniejsze tempo tej metody, a niestety PyOD nie współgra dobrze z PyNNDescent, żeby go przyspieszyć z użyciem ANN. Dlatego skupimy się teraz na Isolation Forest.\n",
    "\n",
    "Jego najważniejsze hiperparametry to:\n",
    "\n",
    "- `n_estimators` - liczba drzew, typowo ok. 500 jest już osiągana asymptota wyniku\n",
    "- `max_samples` - wielkość próbki per drzewo, domyślnie 256, ale nieco większa może pomóc, jeżeli mamy naprawdę masywny zbiór\n",
    "\n",
    "Typowo `contamination` niewiele zmienia w przypadku tego algorytmu, kiedy używamy metryki opartej o prawdopodobieństwa, takiej jak AUPRC.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 6 (1.5 punktu)**\n",
    "\n",
    "1. Dokonaj tuningu hiperarametrów po kolei (step-wise) za pomocą walidacji skrośnej:\n",
    "   - najpierw `n_estimators`, wartości `[100, 200, 300, 400, 500]`\n",
    "   - później `max_samples`, wartości `[100, 200, 256, 300, 400, 500]`\n",
    "   - wykorzystaj wartość `contamination` obliczoną wcześniej\n",
    "   - użyj `random_state=0` i `n_jobs=-1` dla obiektu `IForest`\n",
    "   - użyj 5-krotnej walidacji skrośnej, optymalizując `\"average_precision\"` (AUPRC)\n",
    "2. Wypisz znalezione optymalne wartości parametrów.\n",
    "3. Wytrenuj Isolation Forest z wartościami obu parametrów. Sprawdź wynik na zbiorze testowym.\n",
    "4. Skomentuj, czy udało się poprawić wynik. Czy twoim zdaniem było warto dokonać tuningu obu hiperparamametrów, czy wystarczyłby jeden z nich?\n",
    "\n",
    "**Uwaga:** przez drobnego buga w połączeniu `pyod` i najnowszych wersji Scikit-learn trzeba użyć explicite funkcji obliczającej AUPRC, przygotowano ją poniżej.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "\n",
    "def auprc(estimator, X, y):\n",
    "    return average_precision_score(y, estimator.predict_proba(X))\n",
    "\n",
    "\n",
    "auprc = make_scorer(average_precision_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_estimators': 500}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_samples': 300}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "}\n",
    "\n",
    "n_estimators_grid = GridSearchCV(\n",
    "    IForest(\n",
    "        contamination=contamination, behaviour=\"new\", random_state=0, n_jobs=-1\n",
    "    ),\n",
    "    params,\n",
    "    scoring=auprc,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "n_estimators_grid.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best parameters: {n_estimators_grid.best_params_}\")\n",
    "\n",
    "params = {\n",
    "    'max_samples': [100, 200, 256, 300, 400, 500],\n",
    "}\n",
    "max_samples_grid = GridSearchCV(\n",
    "    IForest(\n",
    "        contamination=contamination, behaviour=\"new\", random_state=0, n_jobs=-1\n",
    "    ),\n",
    "    params,\n",
    "    scoring=auprc,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "max_samples_grid.fit(X_train, y_train)\n",
    "print(f\"Best parameters: {max_samples_grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isolation Forest metrics\n",
      "AUPRC: 57.29%\n"
     ]
    }
   ],
   "source": [
    "forrest = IForest(\n",
    "    n_estimators=500, max_samples=300, contamination=contamination, behaviour=\"new\", random_state=0, n_jobs=-1\n",
    ")\n",
    "forrest.fit(X_train)\n",
    "\n",
    "print(\"Isolation Forest metrics\")\n",
    "assess_anomaly_detection_model(forrest, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wyniki są nieznacznie lepsze, ale ledwo o 1 punkt procentowy. To raczej slaba poprawa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zaprezentowane podejścia należały do **uczenia nienadzorowanego (unsupervised learning)**, gdyż te algorytmy nie potrzebowały klas dla przykładów ze zbioru treningowego. W szczególności Isolation Forest potrafi działać bardzo dobrze nawet wtedy, kiedy zbiór uczący nie zawiera żadnych anomalii. Wykorzystanie takich algorytmów jest zatem proste i tanie, a w szczególności można dla nich łatwo stworzyć potężne zbiory danych.\n",
    "\n",
    "Jeżeli mamy luksus posiadania pełnej informacji o klasach, możemy użyć algorytmów uczenia nadzorowanego (supervised learning). W szczególności można także połączyć te podejścia, co realizuje **uczenie pół-nadzorowane (semi-supervised learning)**, którego przedstawicielem jest XGBoost Outlier Detection (XGBOD). Polega on na obliczeniu anomaly scores dla próbek za pomocą algorytmów nienadzorowanych (np. kNN czy Isolation Forest) i doklejeniu ich jako dodatkowych cech do naszego zbioru treningowego. Można stosować jeden algorytm wielokrotnie, np. kNN dla wielu wartości k, bo wtedy XGBoost ma wiele nowych cech (dla różnych gęstości outlierów) i może je elastycznie łączyć.\n",
    "\n",
    "Tak naprawdę podejście to jest bardzo ogólne, i można by zastosować dowolne połączenia ekstrekcji dodatkowych cech anomalii i klasyfikatorów. XGBOD to po prostu pierwszy zaproponowany przykład takiego algorytmu i działa naprawdę dobrze.\n",
    "\n",
    "PyOD implementuje to w klasie `XGBOD`, która przyjmuje argument `estimator_list`. Jest to lista obiektów klas do nienadzorowanego outlier detection, np. `KNN` czy `IForest` (samych klas, przed treningiem przez `.fit()`). Sam trening i predykcja działa tak jak w przypadku poprzednich algorytmów.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 7 (1.5 punktu)**\n",
    "\n",
    "1. Stwórz listę `estimator_list`, składającą się z:\n",
    "   - algorytmów `KNN` z `n_neighbors`: `[1, 3, 5, 10, 20, 30]`\n",
    "   - algorytmów `IForest` z `n_estimators`: `[50, 100, 200, 300]`\n",
    "   - pamiętaj o przekazaniu `n_jobs=-1` oraz `random_state=0` (w razie potrzeby) podczas tworzenia obiektów tych klas\n",
    "2. Wytrenuj algorytm `XGBOD`, pamiętaj o przekazaniu stworzonego `estimator_list` raz o ustawieniu `n_jobs=-1` i `random_state=0`.\n",
    "3. Dokonaj ewaluacji wyników na zbiorze testowym.\n",
    "4. Skomentuj:\n",
    "   - jak mają się do siebie wyniki podejścia nienadzorowanego i w pełni nadzorowanego?\n",
    "   - co uważasz o podejściu pół-nadzorowanym, w którym skorzystaliśmy z dodatkowych cech?\n",
    "   - czy twoim zdaniem finalna wartość metryki jest zadowalająca?\n",
    "   - czy trening subiektywnie trwał zauważalnie dłużej od tego dla algorytmów nienadzorowanych?\n",
    "   - czy twoim zdaniem warto ponieść wysiłek i koszty, pozwalające na użycie takiego algorytmu pół-nadzorowanego?\n",
    "\n",
    "**Uwaga:** może się to liczyć dość długo, rzędu kilku minut. Jeżeli będzie definitywnie zbyt długie, zmniejsz liczbę algorytmów KNN.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/rzadkows/coding/studies/podstawy-uczenia-maszynowego-24-25/.venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:03:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBOD metrics\n",
      "AUPRC: 91.86%\n"
     ]
    }
   ],
   "source": [
    "from pyod.models.xgbod import XGBOD\n",
    "\n",
    "estimator_list = [\n",
    "    KNN(n_neighbors=n, n_jobs=-1) for n in [1, 3, 5, 10, 20, 30]\n",
    "] + [IForest(n_estimators=n, random_state=0, n_jobs=-1) for n in [50, 100, 200, 300]]\n",
    "\n",
    "xgb = XGBOD(estimator_list=estimator_list, n_jobs=-1, random_state=0)\n",
    "xgb.fit(X_train, y_train)\n",
    "print(\"XGBOD metrics\")\n",
    "assess_anomaly_detection_model(xgb, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wyniki są znacznie lepsze, co pokazuje, że XGBOD działa bardzo dobrze. Podejście pół-nadzorowane jest bardzo ciekawe i daje świetne wyniki. Długość treningu była zdecydowanie dłuższa, ale w tym przypadku była tego warta. Finalny wynik jest juz bardzo bliski idealu i na pewno byłby warty uycia produkcyjnego.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie dodatkowe (3 punkty)\n",
    "\n",
    "W przypadku niektórych zbiorów danych anomalie mogą być zjawiskiem dość pozytywnym, tylko po prostu ekstremalnie rzadkim. Jest tak typowo w farmacji, gdzie molekuły będące potencjalnymi lekami są bardzo niewielkim ułamkiem zbiorów nawet wśród wstępnie typowanych, obiecujących substancji. Pierwszy etap projektowania nowych leków, tzw. high-throughput screening (HTS), polega na identyfikacji tego bardzo niewielkiego podzbioru spośród wielkich baz molekuł, w celu dalszego badania.\n",
    "\n",
    "Zbiór AID746, [dostępny na platformie Kaggle](https://www.kaggle.com/datasets/uciml/bioassay-datasets), dotyczy identyfikacji kinaz białkowych aktywowanych mitogenami ([Wikipedia](https://pl.wikipedia.org/wiki/Kinazy_aktywowane_mitogenami)). Są to enzymy regulujące odpowiedzi na sygnały docierające do komórki, regulujące wiele ciekawych funkcji. Mają potencjalne zastosowania m.in. w rozwoju metod chemoterapii, badaniu insulinoodporności czy rozwoju leków przeciwzapalnych ([Wikipedia](https://en.wikipedia.org/wiki/Mitogen-activated_protein_kinase#As_therapeutic_targets)).\n",
    "\n",
    "W tym zbiorze danych klasa substancji aktywnych stanowi 0.61% zbioru, spośród ok. 57 tysięcy substancji w zbiorze. Jest on już podzielony na część treningową i testową.\n",
    "\n",
    "Dokonaj klasyfikacji oraz tuningu hiperparametrów dla tego zbioru z pomocą:\n",
    "\n",
    "- kNN\n",
    "- Isolation Forest\n",
    "- XGBOD - tu warto zwrócić uwagę też na parametr `scale_pos_weight`, którego dla uproszczenia nie używaliśmy w ostatnim zadaniu\n",
    "\n",
    "Możesz spróbować także użyć undersamplingu, oversamplingu oraz ich połączenia.\n",
    "\n",
    "Jako metryki użyj AUPRC. Podaj także czułość (recall) finalnego algorytmu - w końcu na etapie początkowego filtrowania substancji chcemy na pewno mieć jak najmniej false negatives.\n",
    "\n",
    "Na podstawie wyników oceń, z jakim typem anomalii mamy tu do czynienia. Czy udało się uzyskać zadowalające w twojej ocenie wyniki?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
